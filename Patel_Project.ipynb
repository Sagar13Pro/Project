{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Id :ChinmayNandkishor_Mathakari@student.uml.edu(02007302) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_OneToOneFeatureMixin' from 'sklearn.base' (/Users/sagar/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/02/ncw4xt4d2wd6b1dl7b_g2r9r0000gn/T/ipykernel_7667/3125469616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# License: BSD 3 clause (C) INRIA 2010\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNuSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNuSVR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneClassSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bounds\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml1_min_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_fit_liblinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLibSVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegressorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutlierMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearClassifierMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseCoefMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_libsvm_sparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlibsvm_sparse\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_function_transformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKernelCenterer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboxcox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_OneToOneFeatureMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_OneToOneFeatureMixin' from 'sklearn.base' (/Users/sagar/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import html\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.) Clean and remove short bug reports as in TextClassification.ipynb. Organize the remaining data to a data frame called df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"eclipse_jdt.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df = df[['Issue_id','Priority','Component','Title','Description']]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Title','Description','Priority']]\n",
    "df = df.dropna()\n",
    "df['text'] = df['Title'] + ' ' + df['Description']\n",
    "df = df.drop(columns=['Title','Description'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Method defined to clean text \n",
    "def clean(text):\n",
    "    text = html.unescape(text) # convert html escapes like &amp; to characters.\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text) # tags like <tab>\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text) # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text) # text or code in brackets like [0]\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text) # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text) # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text) # remove any characters other than alphabets\n",
    "    text = re.sub(r'\\s+', ' ', text) # sequences of white spaces\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(clean)\n",
    "df = df[df['text'].str.len() > 50]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.) Generate a balanced data frame called df_balanced from df by restricting the number of entries in the P3 category to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bug reports with priority P3 and sample 5000 rows from it\n",
    "df_sample_P3 = df[df['Priority'] == 'P3'].sample(n = 5000, random_state=123)\n",
    "\n",
    "# Create a separate dataframe containing all other bug reports\n",
    "df_sample_Rest = df[df['Priority'] != 'P3']\n",
    "\n",
    "# Concatenate the two dataframes to create the new balanced bug reports dataset\n",
    "df_balanced = pd.concat([df_sample_Rest, df_sample_P3])\n",
    "\n",
    "# Check the status of the class imbalance\n",
    "df_balanced['Priority'].value_counts()\n",
    "df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.) Lemmatize words and use only 'nav' lemmas for classifications, where 'nav' stands for nouns, pronouns, adjectives, adverbs, and verbs as in FeatureExtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logic for the feature extraction such as nouns, pronouns, adjectives, adverbs and verbs\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "token = list()\n",
    "speech = str(df['text'])\n",
    "doc = nlp(speech)\n",
    "\n",
    "nav = (\"NOUN\", \"VERB\",\"ADJ\",\"ADV\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "print(\"Feature Extraction\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------\")\n",
    "for sent in doc.sents:\n",
    "    for i in sent:\n",
    "        if i.pos_ in nav :\n",
    "            word = re.sub(r\"[,.“”]\", \"\", str(i.lemma_))\n",
    "            word = word.split(\"\\\\n\")\n",
    "            print(f\"Words :   {word}\")\n",
    "            token.append(word[0])\n",
    "            count+=1\n",
    "            \n",
    "print(\"\\nTotal Count : \" , count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_balanced[['text', 'Priority']]\n",
    "df_new = df_new.dropna()\n",
    "print(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Loading the balanced dataframe\n",
    "\n",
    "df_new = df_balanced[['text', 'Priority']]\n",
    "df_new = df_new.dropna()\n",
    "\n",
    "# Step 1 - Data Preparation\n",
    "\n",
    "df_new['text'] = df_new['text'].apply(clean)\n",
    "\n",
    "# Step 2 - Train-Test Split\n",
    "X_train_new, X_test_new, Y_train_new, Y_test_new = train_test_split(df_new['text'],\n",
    "                                                    df_new['Priority'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_new['Priority'])\n",
    "\n",
    "print('Number of Training Data : ', X_train_new.shape[0])\n",
    "print('Number of Test Data : ', X_test_new.shape[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Step 3 - Training the Machine Learning model\n",
    "\n",
    "tfidf_new = TfidfVectorizer(min_df=10, ngram_range=(1, 2), stop_words=\"english\")\n",
    "X_train_new_tf = tfidf_new.fit_transform(X_train_new)\n",
    "\n",
    "model_LSVC_new = LinearSVC(random_state=0, tol=1e-5) ### using LinearSVC\n",
    "model_LSVC_new.fit(X_train_new_tf, Y_train_new)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Step 4 - Model Evaluation\n",
    "\n",
    "X_test_new_tf = tfidf_new.transform(X_test_new)\n",
    "Y_pred_LSVC_new = model_LSVC_new.predict(X_test_new_tf)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Vectorization\n",
    "\n",
    "#tfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,2), stop_words=\"english\")\n",
    "df_new_tf = tfidf_new.fit_transform(df_new['text']).toarray()\n",
    "\n",
    "# Cross Validation with 5 batches (folds)\n",
    "\n",
    "scores = cross_val_score(estimator = model_LSVC_new,\n",
    "                         X = df_new_tf,\n",
    "                         y = df_new['Priority'],\n",
    "                         cv = 5) \n",
    "\n",
    "print (\"Validation scores for each iteration : \", scores)\n",
    "print (\"Mean value of validation scores : \", scores.mean())\n",
    "print (\"Standard deviation of validation scores : \", scores.std())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "training_pipeline = Pipeline(\n",
    "    steps=[('tfidf', TfidfVectorizer(stop_words=\"english\")), \n",
    "           ('LinearSVC', LinearSVC(random_state=21, tol=1e-5))])\n",
    "\n",
    "grid_param = [{\n",
    "'tfidf__min_df': [5, 10],\n",
    "'tfidf__ngram_range': [(1, 3), (1, 6)],\n",
    "'LinearSVC__penalty': ['l2'],\n",
    "'LinearSVC__loss': ['hinge'],\n",
    "'LinearSVC__max_iter': [10000]\n",
    "}, {\n",
    "'tfidf__min_df': [5, 10],\n",
    "'tfidf__ngram_range': [(1, 3), (1, 6)],\n",
    "'LinearSVC__C': [1, 10],\n",
    "'LinearSVC__tol': [1e-2, 1e-3]\n",
    "}]\n",
    "\n",
    "\n",
    "gridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n",
    "                                   param_grid=grid_param,\n",
    "                                   cv=5)\n",
    "\n",
    "gridSearchProcessor.fit(df_balanced['text'], df_balanced['Priority'])\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Grid Search Results : \")\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "best_params = gridSearchProcessor.best_params_\n",
    "print(\"Best_Parameters : \", best_params)\n",
    "\n",
    "best_result = gridSearchProcessor.best_score_\n",
    "print(\"\\n\")\n",
    "print(\"Best_Result : \", best_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "training_pipeline = Pipeline(\n",
    "    steps=[('tfidf', TfidfVectorizer(stop_words=\"english\")), \n",
    "           ('SVC', SVC(random_state=21, tol=1e-5))])\n",
    "\n",
    "tuned_parameters = [{\n",
    "    'tfidf__min_df': [5, 10],\n",
    "    'tfidf__ngram_range': [(1, 3), (1, 6)],\n",
    "    'SVC__C': [1, 10, 100, 1000],\n",
    "    'SVC__kernel': ['rbf', 'linear'], \n",
    "    'SVC__gamma': [1e-3, 1e-4],\n",
    "    \"SVC__tol\": [1e-2, 1e-10]\n",
    "}]\n",
    "\n",
    "gridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n",
    "                                   param_grid=tuned_parameters,\n",
    "                                   cv=2, n_jobs=-1)\n",
    "\n",
    "gridSearchProcessor.fit(df_balanced['text'], df_balanced['Priority'])\n",
    "print()\n",
    "print(\"Grid Search Results : \")\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "best_params_svc = gridSearchProcessor.best_params_\n",
    "print(\"Best_Parameters : \", best_params_svc)\n",
    "\n",
    "best_result_svc = gridSearchProcessor.best_score_\n",
    "print(\"Best_Result : \", best_result_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the balanced dataframe\n",
    "\n",
    "df_new = df_balanced[['text', 'Priority']]\n",
    "df_new = df_new.dropna()\n",
    "\n",
    "# Step 1 - Data Preparation\n",
    "\n",
    "df_new['text'] = df_new['text'].apply(clean)\n",
    "\n",
    "# Step 2 - Train-Test Split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_new['text'],\n",
    "                                                    df_new['Priority'],\n",
    "                                                    test_size=0.2, ### 80-20 train-test split\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_new['Priority'])\n",
    "\n",
    "print('Number of Training Data : ', X_train.shape[0])\n",
    "print('Number of Test Data : ', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,2), stop_words=\"english\") \n",
    "### from sklearn\n",
    "### min_df = 10 means that terms appearing in strickly less than 10 documents are ignored\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "\n",
    "model_LSVC = LinearSVC(random_state=0, tol=1e-5) \n",
    "### tol: Tolerance for stopping criteria; 1e-5 = e^{-5} = exp(-5)\n",
    "model_LSVC.fit(X_train_tf, Y_train)\n",
    "\n",
    "X_test_tf = tfidf.transform(X_test)\n",
    "Y_pred_LSVC = model_LSVC.predict(X_test_tf) ### evaluation\n",
    "print(\"\\n\")\n",
    "print ('Accuracy_Score : ', accuracy_score(Y_test, Y_pred_LSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,2), stop_words=\"english\") \n",
    "### from sklearn\n",
    "### min_df = 10 means that terms appearing in strickly less than 10 documents are ignored\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "\n",
    "model_SVC = SVC(random_state=0, tol=1e-5) \n",
    "### tol: Tolerance for stopping criteria; 1e-5 = e^{-5} = exp(-5)\n",
    "model_SVC.fit(X_train_tf, Y_train)\n",
    "\n",
    "X_test_tf = tfidf.transform(X_test)\n",
    "Y_pred_SVC = model_SVC.predict(X_test_tf) ### evaluation\n",
    "print(\"\\n\")\n",
    "print ('Accuracy_Score : ', accuracy_score(Y_test, Y_pred_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "LSVC_tfidf = TfidfVectorizer(min_df=best_params['tfidf__min_df'],\n",
    "                           ngram_range=best_params['tfidf__ngram_range'],\n",
    "                           stop_words='english')\n",
    "LSVC_X_train_tf = LSVC_tfidf.fit_transform(X_train)\n",
    "\n",
    "\n",
    "best_modal_lsvc=LinearSVC(random_state=21,penalty = 'l2',max_iter = 10000,\n",
    "                          loss= 'hinge')\n",
    "best_modal_lsvc.fit(LSVC_X_train_tf,Y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SVC_tfidf = TfidfVectorizer(min_df = best_params['tfidf__min_df'],\n",
    "                           ngram_range = best_params['tfidf__ngram_range'],\n",
    "                           stop_words = 'english')\n",
    "\n",
    "SVC_X_train_tf = SVC_tfidf.fit_transform(X_train)\n",
    "best_modal_svc = SVC(random_state=21)\n",
    "best_modal_svc.fit(SVC_X_train_tf,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_X_test_tf=LSVC_tfidf.transform(X_test)\n",
    "Y_pred_LSVC=best_modal_lsvc.predict(LSVC_X_test_tf)\n",
    "print ('\\nLinearSVC_Accuracy_Score : ', accuracy_score(Y_test, Y_pred_LSVC))\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print (classification_report(Y_test, Y_pred_LSVC))\n",
    "\n",
    "\n",
    "\n",
    "SVC_X_test_tf=SVC_tfidf.transform(X_test)\n",
    "Y_pred_SVC=best_modal_svc.predict(SVC_X_test_tf)\n",
    "print ('\\nSVC_Accuracy_Score - ', accuracy_score(Y_test, Y_pred_SVC))\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print (classification_report(Y_test, Y_pred_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_modal_SVC = SVC(C = best_params_svc['SVC__C'],\n",
    "                       kernel = 'linear',gamma=best_params_svc['SVC__gamma'],tol=best_params_svc['SVC__tol'],probability=True,random_state=42)\n",
    "\n",
    "linear_modal_SVC.fit(SVC_X_train_tf, Y_train)\n",
    "\n",
    "SVC_X_test_tf = SVC_tfidf.transform(X_test)\n",
    "\n",
    "Y_pred_Linear_Kernal_SVC= linear_modal_SVC.predict(SVC_X_test_tf)\n",
    "print()\n",
    "print ('\\nAccuracy Score - ', accuracy_score(Y_test, Y_pred_Linear_Kernal_SVC))\n",
    "print (classification_report(Y_test, Y_pred_Linear_Kernal_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_modal_SVC=SVC(C = best_params_svc['SVC__C'],kernel = 'rbf',gamma=best_params_svc['SVC__gamma'],tol=best_params_svc['SVC__tol'],probability=True,random_state=42)\n",
    "rbf_modal_SVC.fit(SVC_X_train_tf, Y_train)\n",
    "\n",
    "SVC_X_test_tf=SVC_tfidf.transform(X_test)\n",
    "\n",
    "Y_pred_rbf_Kernal_SVC= rbf_modal_SVC.predict(SVC_X_test_tf)\n",
    "print()\n",
    "print ('\\nAccuracy Score - ', accuracy_score(Y_test, Y_pred_rbf_Kernal_SVC))\n",
    "print (classification_report(Y_test, Y_pred_rbf_Kernal_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_LSVC=best_modal_lsvc.predict(LSVC_X_test_tf)\n",
    "LSVC_results= pd.DataFrame({'text':X_test.values,'actual':Y_test.values,'predicted':Y_pred_LSVC})\n",
    "print(LSVC_results)\n",
    "\n",
    "Y_pred_SVC=model_SVC.predict(X_test_tf)\n",
    "SVC_results=pd.DataFrame({'text':X_test.values,'actual':Y_test.values,'predicted':Y_pred_SVC})\n",
    "print(SVC_results)\n",
    "\n",
    "Y_pred_Linear_Kernal_SVC=linear_modal_SVC.predict(SVC_X_test_tf)\n",
    "Linear_SVC_results=pd.DataFrame({'text':X_test.values,'actual':Y_test.values,'predicted':Y_pred_Linear_Kernal_SVC})\n",
    "\n",
    "Y_pred_rbf_Kernal_SVC=rbf_modal_SVC.predict(SVC_X_test_tf)\n",
    "rbf_SVC_results=pd.DataFrame({'text':X_test.values,'actual':Y_test.values,'predicted':Y_pred_rbf_Kernal_SVC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_modal_SVC.coef_\n",
    "\n",
    "# coef = linear_modal_SVC.coef_[8].A[0]\n",
    "# vocabulary_positions = coef.argsort()\n",
    "# vocabulary = tfidf.get_feature_names()\n",
    "\n",
    "# top_words = 5\n",
    "# top_positive_coef = vocabulary_positions[-top_words:].tolist()\n",
    "# top_negative_coef = vocabulary_positions[:top_words].tolist()\n",
    "# print(top_positive_coef)\n",
    "# print(top_negative_coef)\n",
    "\n",
    "# core_ui = pd.DataFrame([[vocabulary[c], coef[c]] for c in top_positive_coef + top_negative_coef], \n",
    "#                           columns=[\"feature\", \"coefficient\"]).sort_values(\"coefficient\")\n",
    "\n",
    "coef = linear_modal_SVC.coef_[9].A[0]\n",
    "print(coef)\n",
    "vocabulary_positions = coef.argsort()\n",
    "vocabulary = tfidf.get_feature_names()\n",
    "top_words = 5\n",
    "top_positive_coef = vocabulary_positions[-top_words:].tolist()\n",
    "top_negative_coef = vocabulary_positions[:top_words].tolist()\n",
    "print(top_positive_coef)\n",
    "print(top_negative_coef)\n",
    "print(top_positive_coef + top_negative_coef)\n",
    "core_ui = pd.DataFrame([[vocabulary[c], coef[c]] for c in range(len(top_positive_coef+top_negative_coef))], \n",
    "                          columns=[\"feature\", \"coefficient\"]).sort_values(\"coefficient\")\n",
    "core_ui.set_index(\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(tfidf, rbf_modal_SVC)\n",
    "result = pd.DataFrame({ 'text': X_test.values, 'actual': Y_test.values, 'predicted': Y_pred_SVC })\n",
    "class_names = [\"text\", \"predicted\"]\n",
    "prob = rbf_modal_SVC.predict_proba(SVC_X_test_tf)\n",
    "prob_svc = prob\n",
    "# new dataframe for explainable results\n",
    "er = result.copy().reset_index() ### er stands for \"explain result\"\n",
    "explain_result = er\n",
    "er['max_probability'] = er[class_names].max(axis=1)\n",
    "class_names = [\"text\", \"predict\"]\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "er[er[\"predicted\"] != er[\"actual\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
